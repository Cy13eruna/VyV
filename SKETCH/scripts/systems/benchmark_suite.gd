## Benchmark Suite - Sistema de Benchmarks de Performance\n## Executa testes de performance padronizados e gera relatórios comparativos\n\nclass_name BenchmarkSuite\nextends RefCounted\n\nconst PerformanceProfiler = preload(\"res://scripts/systems/performance_profiler.gd\")\nconst GameManagerClass = preload(\"res://scripts/game/game_manager.gd\")\nconst ResultClass = preload(\"res://scripts/core/result.gd\")\n\n# Singleton pattern\nstatic var instance: BenchmarkSuite\n\n# Resultados dos benchmarks\nvar benchmark_results: Dictionary = {}\nvar baseline_results: Dictionary = {}\nvar comparison_results: Dictionary = {}\n\n# Configurações\nvar iterations_per_benchmark: int = 1000\nvar warmup_iterations: int = 100\nvar enable_detailed_logging: bool = false\n\n# Profiler\nvar profiler: PerformanceProfiler\n\nstatic func get_instance() -> BenchmarkSuite:\n\tif not instance:\n\t\tinstance = BenchmarkSuite.new()\n\treturn instance\n\nfunc _init():\n\tif not instance:\n\t\tinstance = self\n\tprofiler = PerformanceProfiler.get_instance()\n\nfunc run_all_benchmarks() -> Dictionary:\n\t\"\"\"Executa todos os benchmarks e retorna resultados\"\"\"\n\tprint(\"🏁 Iniciando Suite de Benchmarks de Performance...\")\n\t\n\tprofiler.start_profiling()\n\t\n\t# Benchmarks de criação de objetos\n\tbenchmark_object_creation()\n\t\n\t# Benchmarks de operações de array\n\tbenchmark_array_operations()\n\t\n\t# Benchmarks de operações de dictionary\n\tbenchmark_dictionary_operations()\n\t\n\t# Benchmarks de sistema Result<T>\n\tbenchmark_result_system()\n\t\n\t# Benchmarks de GameManager\n\tbenchmark_game_manager_operations()\n\t\n\t# Benchmarks de validação de terreno\n\tbenchmark_terrain_validation()\n\t\n\t# Benchmarks de movimento de unidades\n\tbenchmark_unit_movement()\n\t\n\t# Benchmarks de memória\n\tbenchmark_memory_operations()\n\t\n\tprofiler.stop_profiling()\n\t\n\tprint(\"✅ Suite de Benchmarks concluída!\")\n\treturn benchmark_results\n\nfunc benchmark_object_creation():\n\t\"\"\"Benchmark de criação de objetos\"\"\"\n\tprint(\"📦 Benchmark: Criação de Objetos\")\n\t\n\t# Warmup\n\tfor i in range(warmup_iterations):\n\t\tvar obj = RefCounted.new()\n\t\n\t# Benchmark de RefCounted\n\tvar start_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark):\n\t\tvar obj = RefCounted.new()\n\tvar end_time = Time.get_ticks_usec()\n\tvar refcounted_time = (end_time - start_time) / 1000.0  # ms\n\t\n\t# Benchmark de Dictionary\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark):\n\t\tvar dict = {}\n\tend_time = Time.get_ticks_usec()\n\tvar dictionary_time = (end_time - start_time) / 1000.0  # ms\n\t\n\t# Benchmark de Array\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark):\n\t\tvar array = []\n\tend_time = Time.get_ticks_usec()\n\tvar array_time = (end_time - start_time) / 1000.0  # ms\n\t\n\tbenchmark_results[\"object_creation\"] = {\n\t\t\"refcounted_ms\": refcounted_time,\n\t\t\"dictionary_ms\": dictionary_time,\n\t\t\"array_ms\": array_time,\n\t\t\"refcounted_per_sec\": iterations_per_benchmark / (refcounted_time / 1000.0),\n\t\t\"dictionary_per_sec\": iterations_per_benchmark / (dictionary_time / 1000.0),\n\t\t\"array_per_sec\": iterations_per_benchmark / (array_time / 1000.0)\n\t}\n\t\n\tif enable_detailed_logging:\n\t\tprint(\"  RefCounted: %.2f ms (%.0f/sec)\" % [refcounted_time, benchmark_results.object_creation.refcounted_per_sec])\n\t\tprint(\"  Dictionary: %.2f ms (%.0f/sec)\" % [dictionary_time, benchmark_results.object_creation.dictionary_per_sec])\n\t\tprint(\"  Array: %.2f ms (%.0f/sec)\" % [array_time, benchmark_results.object_creation.array_per_sec])\n\nfunc benchmark_array_operations():\n\t\"\"\"Benchmark de operações com arrays\"\"\"\n\tprint(\"📊 Benchmark: Operações de Array\")\n\t\n\t# Preparar dados\n\tvar test_array = []\n\tfor i in range(1000):\n\t\ttest_array.append(i)\n\t\n\t# Benchmark de append\n\tvar start_time = Time.get_ticks_usec()\n\tvar append_array = []\n\tfor i in range(iterations_per_benchmark):\n\t\tappend_array.append(i)\n\tvar end_time = Time.get_ticks_usec()\n\tvar append_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de acesso por índice\n\tstart_time = Time.get_ticks_usec()\n\tvar sum = 0\n\tfor i in range(iterations_per_benchmark):\n\t\tsum += test_array[i % test_array.size()]\n\tend_time = Time.get_ticks_usec()\n\tvar access_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de busca linear\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark / 10):  # Menos iterações para busca\n\t\tvar found = test_array.find(i % 100)\n\tend_time = Time.get_ticks_usec()\n\tvar search_time = (end_time - start_time) / 1000.0\n\t\n\tbenchmark_results[\"array_operations\"] = {\n\t\t\"append_ms\": append_time,\n\t\t\"access_ms\": access_time,\n\t\t\"search_ms\": search_time,\n\t\t\"append_per_sec\": iterations_per_benchmark / (append_time / 1000.0),\n\t\t\"access_per_sec\": iterations_per_benchmark / (access_time / 1000.0),\n\t\t\"search_per_sec\": (iterations_per_benchmark / 10) / (search_time / 1000.0)\n\t}\n\nfunc benchmark_dictionary_operations():\n\t\"\"\"Benchmark de operações com dicionários\"\"\"\n\tprint(\"🗂️ Benchmark: Operações de Dictionary\")\n\t\n\t# Preparar dados\n\tvar test_dict = {}\n\tfor i in range(1000):\n\t\ttest_dict[\"key_%d\" % i] = i\n\t\n\t# Benchmark de inserção\n\tvar start_time = Time.get_ticks_usec()\n\tvar insert_dict = {}\n\tfor i in range(iterations_per_benchmark):\n\t\tinsert_dict[\"key_%d\" % i] = i\n\tvar end_time = Time.get_ticks_usec()\n\tvar insert_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de acesso\n\tstart_time = Time.get_ticks_usec()\n\tvar sum = 0\n\tfor i in range(iterations_per_benchmark):\n\t\tvar key = \"key_%d\" % (i % 1000)\n\t\tif test_dict.has(key):\n\t\t\tsum += test_dict[key]\n\tend_time = Time.get_ticks_usec()\n\tvar access_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de verificação de existência\n\tstart_time = Time.get_ticks_usec()\n\tvar exists_count = 0\n\tfor i in range(iterations_per_benchmark):\n\t\tvar key = \"key_%d\" % (i % 1000)\n\t\tif test_dict.has(key):\n\t\t\texists_count += 1\n\tend_time = Time.get_ticks_usec()\n\tvar has_time = (end_time - start_time) / 1000.0\n\t\n\tbenchmark_results[\"dictionary_operations\"] = {\n\t\t\"insert_ms\": insert_time,\n\t\t\"access_ms\": access_time,\n\t\t\"has_ms\": has_time,\n\t\t\"insert_per_sec\": iterations_per_benchmark / (insert_time / 1000.0),\n\t\t\"access_per_sec\": iterations_per_benchmark / (access_time / 1000.0),\n\t\t\"has_per_sec\": iterations_per_benchmark / (has_time / 1000.0)\n\t}\n\nfunc benchmark_result_system():\n\t\"\"\"Benchmark do sistema Result<T>\"\"\"\n\tprint(\"✅ Benchmark: Sistema Result<T>\")\n\t\n\t# Benchmark de criação de Result de sucesso\n\tvar start_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark):\n\t\tvar result = ResultClass.success(i)\n\tvar end_time = Time.get_ticks_usec()\n\tvar success_creation_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de criação de Result de erro\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark):\n\t\tvar result = ResultClass.error(\"Error %d\" % i)\n\tend_time = Time.get_ticks_usec()\n\tvar error_creation_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de verificação de sucesso\n\tvar test_results = []\n\tfor i in range(100):\n\t\ttest_results.append(ResultClass.success(i))\n\t\ttest_results.append(ResultClass.error(\"Error %d\" % i))\n\t\n\tstart_time = Time.get_ticks_usec()\n\tvar success_count = 0\n\tfor i in range(iterations_per_benchmark):\n\t\tvar result = test_results[i % test_results.size()]\n\t\tif result.is_success():\n\t\t\tsuccess_count += 1\n\tend_time = Time.get_ticks_usec()\n\tvar check_time = (end_time - start_time) / 1000.0\n\t\n\tbenchmark_results[\"result_system\"] = {\n\t\t\"success_creation_ms\": success_creation_time,\n\t\t\"error_creation_ms\": error_creation_time,\n\t\t\"check_ms\": check_time,\n\t\t\"success_per_sec\": iterations_per_benchmark / (success_creation_time / 1000.0),\n\t\t\"error_per_sec\": iterations_per_benchmark / (error_creation_time / 1000.0),\n\t\t\"check_per_sec\": iterations_per_benchmark / (check_time / 1000.0)\n\t}\n\nfunc benchmark_game_manager_operations():\n\t\"\"\"Benchmark de operações do GameManager\"\"\"\n\tprint(\"🎮 Benchmark: Operações do GameManager\")\n\t\n\t# Criar GameManager mock\n\tvar game_manager = GameManagerClass.new()\n\t\n\t# Benchmark de criação de unidades\n\tvar start_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark / 10):  # Menos iterações para operações complexas\n\t\tvar result = game_manager.create_unit()\n\tend_time = Time.get_ticks_usec()\n\tvar unit_creation_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de obtenção de todas as unidades\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark):\n\t\tvar units = game_manager.get_all_units()\n\tend_time = Time.get_ticks_usec()\n\tvar get_units_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de limpeza\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark / 100):  # Muito menos iterações\n\t\tgame_manager.clear_all_units()\n\tend_time = Time.get_ticks_usec()\n\tvar cleanup_time = (end_time - start_time) / 1000.0\n\t\n\tbenchmark_results[\"game_manager\"] = {\n\t\t\"unit_creation_ms\": unit_creation_time,\n\t\t\"get_units_ms\": get_units_time,\n\t\t\"cleanup_ms\": cleanup_time,\n\t\t\"unit_creation_per_sec\": (iterations_per_benchmark / 10) / (unit_creation_time / 1000.0),\n\t\t\"get_units_per_sec\": iterations_per_benchmark / (get_units_time / 1000.0),\n\t\t\"cleanup_per_sec\": (iterations_per_benchmark / 100) / (cleanup_time / 1000.0)\n\t}\n\nfunc benchmark_terrain_validation():\n\t\"\"\"Benchmark de validação de terreno\"\"\"\n\tprint(\"🗺️ Benchmark: Validação de Terreno\")\n\t\n\t# Mock de SharedGameState para teste\n\tvar mock_shared_state = MockSharedGameState.new()\n\t\n\t# Benchmark de validação de movimento\n\tvar start_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark):\n\t\tvar from_star = i % 49\n\t\tvar to_star = (i + 1) % 49\n\t\tvar is_valid = mock_shared_state.is_movement_valid(from_star, to_star)\n\tend_time = Time.get_ticks_usec()\n\tvar validation_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de cálculo de estrelas adjacentes\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark / 10):\n\t\tvar star_id = i % 49\n\t\tvar adjacent = mock_shared_state.get_adjacent_stars(star_id)\n\tend_time = Time.get_ticks_usec()\n\tvar adjacent_time = (end_time - start_time) / 1000.0\n\t\n\tbenchmark_results[\"terrain_validation\"] = {\n\t\t\"validation_ms\": validation_time,\n\t\t\"adjacent_ms\": adjacent_time,\n\t\t\"validation_per_sec\": iterations_per_benchmark / (validation_time / 1000.0),\n\t\t\"adjacent_per_sec\": (iterations_per_benchmark / 10) / (adjacent_time / 1000.0)\n\t}\n\nfunc benchmark_unit_movement():\n\t\"\"\"Benchmark de movimento de unidades\"\"\"\n\tprint(\"⚔️ Benchmark: Movimento de Unidades\")\n\t\n\t# Criar unidades mock para teste\n\tvar mock_units = []\n\tfor i in range(100):\n\t\tmock_units.append(MockUnit.new(i % 49))\n\t\n\t# Benchmark de obtenção de movimentos válidos\n\tvar start_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark / 10):\n\t\tvar unit = mock_units[i % mock_units.size()]\n\t\tvar valid_moves = _get_mock_valid_moves(unit)\n\tend_time = Time.get_ticks_usec()\n\tvar valid_moves_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de execução de movimento\n\tstart_time = Time.get_ticks_usec()\n\tfor i in range(iterations_per_benchmark / 10):\n\t\tvar unit = mock_units[i % mock_units.size()]\n\t\tvar new_position = (unit.current_star_id + 1) % 49\n\t\tunit.move_to_star(new_position)\n\tend_time = Time.get_ticks_usec()\n\tvar movement_time = (end_time - start_time) / 1000.0\n\t\n\tbenchmark_results[\"unit_movement\"] = {\n\t\t\"valid_moves_ms\": valid_moves_time,\n\t\t\"movement_ms\": movement_time,\n\t\t\"valid_moves_per_sec\": (iterations_per_benchmark / 10) / (valid_moves_time / 1000.0),\n\t\t\"movement_per_sec\": (iterations_per_benchmark / 10) / (movement_time / 1000.0)\n\t}\n\nfunc benchmark_memory_operations():\n\t\"\"\"Benchmark de operações de memória\"\"\"\n\tprint(\"🧠 Benchmark: Operações de Memória\")\n\t\n\t# Benchmark de alocação de memória\n\tvar start_time = Time.get_ticks_usec()\n\tvar memory_objects = []\n\tfor i in range(iterations_per_benchmark / 10):\n\t\tmemory_objects.append(PackedByteArray())\n\t\tmemory_objects[-1].resize(1024)  # 1KB por objeto\n\tend_time = Time.get_ticks_usec()\n\tvar allocation_time = (end_time - start_time) / 1000.0\n\t\n\t# Benchmark de acesso à memória\n\tstart_time = Time.get_ticks_usec()\n\tvar sum = 0\n\tfor i in range(iterations_per_benchmark):\n\t\tif memory_objects.size() > 0:\n\t\t\tvar obj = memory_objects[i % memory_objects.size()]\n\t\t\tif obj.size() > 0:\n\t\t\t\tsum += obj[0]\n\tend_time = Time.get_ticks_usec()\n\tvar access_time = (end_time - start_time) / 1000.0\n\t\n\t# Limpeza\n\tmemory_objects.clear()\n\t\n\tbenchmark_results[\"memory_operations\"] = {\n\t\t\"allocation_ms\": allocation_time,\n\t\t\"access_ms\": access_time,\n\t\t\"allocation_per_sec\": (iterations_per_benchmark / 10) / (allocation_time / 1000.0),\n\t\t\"access_per_sec\": iterations_per_benchmark / (access_time / 1000.0)\n\t}\n\nfunc save_baseline(name: String = \"default\"):\n\t\"\"\"Salva resultados atuais como baseline\"\"\"\n\tbaseline_results[name] = benchmark_results.duplicate(true)\n\tprint(\"💾 Baseline '%s' salvo com %d benchmarks\" % [name, benchmark_results.size()])\n\nfunc compare_with_baseline(baseline_name: String = \"default\") -> Dictionary:\n\t\"\"\"Compara resultados atuais com baseline\"\"\"\n\tif not baseline_results.has(baseline_name):\n\t\tprint(\"⚠️ Baseline '%s' não encontrado\" % baseline_name)\n\t\treturn {}\n\t\n\tvar baseline = baseline_results[baseline_name]\n\tvar comparison = {}\n\t\n\tfor benchmark_name in benchmark_results.keys():\n\t\tif baseline.has(benchmark_name):\n\t\t\tvar current = benchmark_results[benchmark_name]\n\t\t\tvar base = baseline[benchmark_name]\n\t\t\tvar bench_comparison = {}\n\t\t\t\n\t\t\tfor metric in current.keys():\n\t\t\t\tif base.has(metric) and current[metric] > 0 and base[metric] > 0:\n\t\t\t\t\tvar ratio = current[metric] / base[metric]\n\t\t\t\t\tvar percent_change = (ratio - 1.0) * 100.0\n\t\t\t\t\t\n\t\t\t\t\tbench_comparison[metric] = {\n\t\t\t\t\t\t\"current\": current[metric],\n\t\t\t\t\t\t\"baseline\": base[metric],\n\t\t\t\t\t\t\"ratio\": ratio,\n\t\t\t\t\t\t\"percent_change\": percent_change,\n\t\t\t\t\t\t\"improved\": ratio > 1.0 if metric.ends_with(\"_per_sec\") else ratio < 1.0\n\t\t\t\t\t}\n\t\t\t\n\t\t\tcomparison[benchmark_name] = bench_comparison\n\t\n\tcomparison_results = comparison\n\treturn comparison\n\nfunc generate_benchmark_report() -> String:\n\t\"\"\"Gera relatório completo dos benchmarks\"\"\"\n\tvar report = \"🏁 RELATÓRIO DE BENCHMARKS DE PERFORMANCE\\n\"\n\treport += \"=\" * 60 + \"\\n\\n\"\n\t\n\treport += \"⚙️ CONFIGURAÇÃO:\\n\"\n\treport += \"Iterações por benchmark: %d\\n\" % iterations_per_benchmark\n\treport += \"Iterações de warmup: %d\\n\" % warmup_iterations\n\treport += \"\\n\"\n\t\n\t# Resultados por categoria\n\tfor benchmark_name in benchmark_results.keys():\n\t\treport += \"📊 %s:\\n\" % benchmark_name.to_upper().replace(\"_\", \" \")\n\t\tvar results = benchmark_results[benchmark_name]\n\t\t\n\t\tfor metric in results.keys():\n\t\t\tvar value = results[metric]\n\t\t\tif metric.ends_with(\"_ms\"):\n\t\t\t\treport += \"  %s: %.2f ms\\n\" % [metric.replace(\"_ms\", \"\"), value]\n\t\t\telif metric.ends_with(\"_per_sec\"):\n\t\t\t\treport += \"  %s: %.0f ops/sec\\n\" % [metric.replace(\"_per_sec\", \"\"), value]\n\t\t\n\t\treport += \"\\n\"\n\t\n\t# Comparação com baseline se disponível\n\tif comparison_results.size() > 0:\n\t\treport += \"📈 COMPARAÇÃO COM BASELINE:\\n\"\n\t\tfor benchmark_name in comparison_results.keys():\n\t\t\treport += \"  %s:\\n\" % benchmark_name\n\t\t\tvar comparison = comparison_results[benchmark_name]\n\t\t\t\n\t\t\tfor metric in comparison.keys():\n\t\t\t\tvar comp = comparison[metric]\n\t\t\t\tvar status = \"📈\" if comp.improved else \"📉\"\n\t\t\t\treport += \"    %s %s: %+.1f%%\\n\" % [status, metric, comp.percent_change]\n\t\t\t\n\t\t\treport += \"\\n\"\n\t\n\treport += \"=\" * 60 + \"\\n\"\n\treport += \"Relatório gerado em: %s\\n\" % Time.get_datetime_string_from_system()\n\t\n\treturn report\n\nfunc _get_mock_valid_moves(unit) -> Array:\n\t\"\"\"Simula obtenção de movimentos válidos\"\"\"\n\tvar moves = []\n\tvar current = unit.current_star_id\n\t\n\t# Simular algumas posições adjacentes\n\tfor i in range(3):\n\t\tvar adjacent = (current + i + 1) % 49\n\t\tmoves.append(adjacent)\n\t\n\treturn moves\n\n# Mock classes para benchmarks\nclass MockSharedGameState:\n\tfunc is_movement_valid(from_star: int, to_star: int) -> bool:\n\t\t# Simulação simples\n\t\treturn abs(from_star - to_star) <= 1\n\t\n\tfunc get_adjacent_stars(star_id: int) -> Array:\n\t\t# Simulação simples\n\t\tvar adjacent = []\n\t\tfor i in range(3):\n\t\t\tadjacent.append((star_id + i + 1) % 49)\n\t\treturn adjacent\n\nclass MockUnit:\n\tvar current_star_id: int\n\t\n\tfunc _init(star_id: int):\n\t\tcurrent_star_id = star_id\n\t\n\tfunc move_to_star(star_id: int):\n\t\tcurrent_star_id = star_id\n\t\treturn true\n\nfunc cleanup():\n\t\"\"\"Limpa recursos do benchmark\"\"\"\n\tbenchmark_results.clear()\n\tbaseline_results.clear()\n\tcomparison_results.clear()\n\tinstance = null\n"